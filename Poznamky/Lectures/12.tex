\documentclass[../main.tex]{subfiles}

%{definition}{Definice}
%{example}{Příklad}
%{intuition}{Intuice}
%{remark}{Poznámka}
%{consequence}{Důsledek}
%{observation}{Pozorování}

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Dvanáctá přednáška}

\subsection{Testování hypotéz - ilustrace}
\begin{itemize}
    \item Chceme testovat, zda je mince spravedlivá.
    \item $H_0:$ je spravedlivá - očekávaný stav světa
    \item $H_1:$ není spravedlivá - překvapivé zjištění
    \item Výsledky. zamítneme $H_0$ / nezamítneme $H_0$
    \item Chyba 1. druhu: chybné zamítnutí. Zamítneme $H_0$, i když platí. Trapas.
    \item Chyba 2. druhu: chybné přijetí. Nezamítneme $H_0$, ale ona neplatí. Promarněná příležitost.
    \item Potřebujeme určit $k$ takové, že budeme zamítat $H_0$ pokud \textbf{DOPLNIT}
\end{itemize}
\begin{itemize}
    \item Vybereme vhodný statistický model.
    \item Volíme hladinu významnosti (significance level) $\alpha$: pravd. chybného zamítnutí $H_0$. Typicky $\alpha = 0.05$.
    \item Určíme testovou statistiku $T = h(X_1,\dots,X_n)$, kterou budeme určovat z naměřených dat.
    \item Určíme kritický obor (rejection region) - množinu $W$.
    \item Naměříme hodnoty $x_1,\dots,x_n$ náh. veličin $X_1,\dots,X_n$.
    \item Rozhodovací pravidlo: zamítneme $H_0$ pokud $h(x_1,\dots,x_n) \in W$.
    \item $\alpha = P(h(X) \in W; H_0)$
    \item $\beta = P(h(X) \notin W; H_1) \dots 1 - \beta$ je tzv. síla testu
    \item často $\alpha$ nevolíme předem, ale spočítáme tzv. $p$-hodnotu: minimální $\alpha$, pro které bychom $H_0$ zamítli.
\end{itemize}

\begin{example}
    Měříme teplotu, chceme $\mu = 5$°C
    \begin{itemize}
        \item $X_1,\dots,X_n$ náhodný výběr z $H(\vartheta,\sigma^2)$
        \item $\sigma^2$ známe, $\mu$ dáno
        \item $H_0 : \vartheta = \mu$, $H_1: \vartheta \neq \mu$
    \end{itemize}
    \[T = \frac{X_1+\dots+X_n}{\mu} = \overline{X}_n \sim N(\vartheta, \sigma^2/n)\]
    ... víme ze vzorce pro rozptyl
    \[S = \frac{\overline{X_n} - \mu}{\sigma/\sqrt{n}} \sim N(0,1)\]
    vezmeme množinu:
    \[W := \{s\in R : |s| > Z_{\alpha/2}\}\]
    kde $z_{\alpha/2} = \Phi^{-1}(1-\frac{\alpha}{2})$... pro $\alpha = 0.05$ dostaneme $1.96$
\end{example}

\begin{example}[příklad dvojvýběrového testu]
    {\color{white} x}
    \begin{itemize}
        \item $X_1,\dots,X_{n_1}$ náhodný výběr z $Ber(\vartheta_X)$
        \item $Y_1,\dots,Y_{n_2}$ náhodný výběr z $Ber(\vartheta_Y)$
        \item $H_0 : \vartheta_X = \vartheta_Y$ \dots $H_1 : \vartheta_X \neq \vartheta_Y$
    \end{itemize}
    Máme $n_1$ lidí a jiných $n_2$ lidí které léčíme různými metodami ($H_0$ vs $H_1$)
    \[\widehat{\Theta}_X = \frac{X_1 +\dots + X_{n_1}}{n_1} \dots \text{odhad }\vartheta_X\]
\[\widehat{\Theta}_Y = \frac{Y_1 +\dots + Y_{n_2}}{n_2} \dots \text{odhad }\vartheta_Y\]
    \[Z := \widehat{\Theta}_X - \widehat{\Theta}_Y\]
    $\widehat{\Theta}_X, \widehat{\Theta}_Y$ mají přibližně normální rozdělení (Centrální limitní věta)

    Předpokládáme, že platí $H_0$:
    \[\mathbb{E}\widehat{\Theta}_X = \mathbb{E}\widehat{\Theta}_Y \implies
    \mathbb{E}Z = 0\]
    Víme, že $Z$ je přibližně $N(0,\sigma^2)$, $\sigma^2$ neznáme
    \[\sigma^2 = var(Z) = var(\widehat{\Theta}_X) - var(\widehat{\Theta}_Y) =
    \frac{var X_1}{n_1} + \frac{var Y_1}{n_2} =
\frac{\vartheta_X(1-\vartheta_X)}{n_1} + \frac{\vartheta_Y(1-\vartheta_Y)}{n_1}
= \vartheta\left(\frac{1}{n_1} + \frac{1}{n_2}\right)\]
    \[\widehat{\Theta} = \frac{\sum X_i + \sum Y_j}{n_1 + n_2} \dots \text{
    odhad }\vartheta \implies \widehat{\sigma^2} := \left(\frac{1}{n_1} +
\frac{1}{n_2}\right) \widehat{\Theta} (1- \widehat{\Theta}) \implies T:=
\frac{\widehat{\Theta}_X - \widehat{\Theta}_Y}{\widehat{\sigma}}\]
\end{example}

\subsection{$p$-hacking}
\begin{itemize}
    \item napřed získáme data, pak v nich hledáme zajímavosti
    \item když máme dost dat, tak tam nějaké budou "shodou okolností"
    \item reprodukovatelnost - po explorační analýze dat uděláme nezávislý sběr dat a ten analyzujeme konfirmačně
    \item nebo dopředu náhodně rozdělíme data na část pro tvorbu hypotéz a část pro jejich potvrzení \dots jednoduchý případ křížové validace (cross validation)
\end{itemize}

\subsection{$\chi^2_k$ - rozdělení $\chi$-kvadrát}
\begin{definition}[$\chi^2_k$ - rozdělení $\chi$-kvadrát]
    $Z_1,\dots,Z_k \sim N(0,1)$ n.n.v. Rozdělení náhodné veličiny
    \[Q = Z^2_1 + \dots + Z^2_k\]
    se nazývá $\chi$-kvadrát s $k$ stupni volnosti.
    \begin{itemize}
        \item $\mathbb{E}(Q) = k$
        \item $var(Q) = 2k$
        \item hustota jde napsat vzorcem, lze najít např. na Wikipedii
        \item $Q \dot{=} N(k,2k)$ pro velká $k$ (CLV)
    \end{itemize}
\end{definition}

\subsection{Multinomické a kategoriální rozdělení}
\begin{definition}
    Dána $p_1,\dots,p_k \geq 0$ a tak, že $p_1 + p_2 + \dots + p_k = 1$.
    
    $n$-krát zopakuji pokus, kde může nastat jedna z $k$ možností, $i$-tá má pravděpodobnost $p_i$.

    $X_i :=$ kolikrát nastala $i$-tá možnost $(X_1,\dots,X_k)$ má multinomické rozdělení s parametry $n,(p_1,\dots,p_k).$
    \begin{itemize}
        \item triviální případ: $X_i = $ počet hodů kostkou, kdy padlo $i$
        \item důležitý případ: $X_i = $ počet výskytů $i-$tého písmene, $i-$tého slovního druhu, \dots
        \item $P(X_1 = x_1, \dots , X_k = x_k) = {{n}\choose{x_1,\dots ,x_k}}p_{1}^{x_1}\dots p_{k}^{x_k}$
    \end{itemize}
\end{definition}

\begin{definition}[Pearsonova $\chi^2$ Statistika]\
    \begin{itemize}
        \item $(X_1,\dots,X_k)$ - multinomické rozdělení s parametry $n, (p_1,\dots,p_k)$ jako minule
        \item $\mathbb{E}_i = \mathbb{E}(X_i) = np_i$
        \item Pearsonova $\chi^2$ statisika je funkce
    \end{itemize}
    \[\chi^2 = T:= \sum^k_{i=1} \frac{(X_i - E_i)^2}{E_i}\]
\end{definition}


\begin{theorem}
    $T \rightarrow^d \chi^2_{k-1}$
\end{theorem}
\begin{proof}
    pro $k=2$
    \[X_1 + X_2 = n, p_1 + p_2 = 1, E_i = np_i\]
    \[T = \frac{(X_1 - E_1)^2}{E_1} + \dots = \frac{(X_1 - np_1)^2 + (p_1 + p_2)}{np_1p_2}\]
    \[ = \left(\frac{X_1 - np_1}{\sqrt{np - (1-p_1)}}\right)\]
\end{proof}

\subsection{Test dobré shody (goodness of fit)}
\begin{itemize}
    \item $(X_1,\dots,X_k)$ - multinomické rozdělení s parametry $n,\vartheta =
        (\vartheta_1,\dots,\vartheta_k)$ jako minule
    \item $n$ známe, $\varphi$ neznáme.
    \item Hypotéza $H_0: \vartheta = \vartheta^*$
    \item $E_i := n\vartheta^*_i$ pro všechna $i$
    \item Použijeme statistiku $\chi^2 = T:= \sum^k_{i=1} \frac{(X_i-E_i)^2}{E_i}$
    \item Hyotézu $H_0$ zamítneme, pokud $T > \gamma$
    \item $\gamma := F^{-1}_Q (1-\alpha)$, kde $Q \sim \chi^2_{k-1}$
    \item $P$(chyba prvního druhu)$ = P(T > \gamma; H_0) \rightarrow P(Q>\gamma) = \alpha$
\end{itemize}
\begin{example}[Test dobré shody - házíme kostkou]\
    \begin{itemize}
        \item Házíme opakovaně kostkou. Jednotlivá čísla padla s četností 92,120,88,98,95 a 107.
        \item Je kostka spravedlivá?
    \end{itemize}
    \[ n = 92 + 120 +\dots = 600\]
    \[\vartheta^* = \left(\frac{1}{6}, \dots, \frac{1}{6}\right),\ E_i = n \frac{1}{6} = 100\]
    \[T = \sum^6_{i=1} \frac{(X_i - 100)^2}{100} = \dots = \frac{(80^2 + 20^2 +
    12^2 + 2^2 + 5^2 + 7^2)}{100} = 6.86\]
    \[Q \sim \chi^2_5 \dots F^{-1}_Q (1 - \alpha = 0.95) = 11.1\]
    kdyby nám T vyšlo víc než 11.1, můžeme říct, že kostka je nespravedlivá.
    \[p-\text{hodnota}: 1-F_Q(6.86) \dot{=} 1 - 0.77 = 0.23\]
    zhruba ve čtvrtině hodů najdeme extremnejší odchylku.
\end{example}

Další rozšíření
\begin{itemize}
    \item Pro zkoumání rozdělení libovolné n.v. $Y$ můžeme vybrat "přihrádky" $B_1,\dots,B_k$ (rozklad $\mathcal{R}$) a zkoumat, kolikrát je $Y \in B_i$
    \item Obdobný test pro nezávislost (diskrétních) náhodných veličin 
\end{itemize}

\begin{definition}[Lineární regrese]
    {\color{white} x}
    \begin{itemize}
        \item data: $(x_i,y_i)$ pro $i=1,\dots,n$
        \item \textbf{TODO} 
    \end{itemize}
\end{definition}
\end{document}
