\documentclass[../main.tex]{subfiles}

%{definition}{Definice}
%{example}{Příklad}
%{intuition}{Intuice}
%{remark}{Poznámka}
%{consequence}{Důsledek}
%{observation}{Pozorování}

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Osmá přednáška}

\begin{definition}
    Podmíňování\\

    zúžení náhodné veličiny na množinu: $X$ je n.v. na $(\Omega, \mathcal{F},P), B \in \mathcal{F}$, t. ž. $P(B) >0$.
    \[F_{X|B}(x):= P(X \leq x |B)\]
    K tomu příslušní hustotní funkce $f_{X|B}$:\\
    Pokud $B = \{X\in S\},$ tak 
    \[f_{X|B}(x) = 
    \begin{cases}    
        \frac{f_X(x)}{P(X\in S)} \dots \text{ pokud } x\in S\\
        0 \dots \text{ jinak }
    \end{cases}\]
\end{definition}
\begin{theorem}
    Věta o rozkladu hustoty\\

    Nechť $X$ je spojitá n.v., nechť $B_1,B_2,\dots$ je rozklad $\Omega$. Pak
    \[F_X(x) = \sum_i P(B_i)F_{X|B_i}(x),\]
    \[f_X(x) = \sum_i P(B_i)f_{X|B_i}(x).\]
    \begin{proof}
        věta o úplné pravděpodobnosti. 
        \[P(X\leq x) = \sum P(\dots)\]
    \end{proof}
\end{theorem}

\begin{theorem}
    Marginální hustota\\

    \[f_X(x) = \int_{y\in \mathbb{R}} f_{X,Y}(x,y)dy\]
    \[f_Y(y) = \int_{x\in \mathbb{R}} f_{X,Y}(x,y)dx\]
\end{theorem}
\begin{proof}
    \textbf{TODO}
\end{proof}

\begin{definition}
    Podmíněná hustota\\

    Pro spojité n.v. $X,Y$ definujeme podmíněnou hustotu předpisem
    \[f_{X|Y}(x|y) = \frac{f_{X,Y}(x,y)}{f_{Y}(y)}\]
    pokud je $f_Y(y) > 0$, jinak ji nedefinujeme.
    \begin{enumerate}
        \item připomeňme, že $f_Y(y) = \int_{x\in \mathbb{R}}f_{X,Y}(x,y)dx$
        \item pro fixované $y$ je $f_{X|Y}(x|y)$ hustota.
    \end{enumerate}
\end{definition}
\begin{theorem}
    Podmíněná, sdružená a marginální hustota\\

    \[f_{X,Y}(x,y) = f_Y(y)f_{X|Y}(x|y)\]
    \[f_X(x) = \int^\infty_{-\infty} f_{X,Y}(x|y)f_Y(y)\,dy\]
\end{theorem}

\begin{theorem}
    Součet spojitých n.v.\\

    Nechť spojité $X,Y$ jsou n.n.v. Pak $Z = X+Y$ je také spojitá n.v. a její hustotu dostaneme jako konvoluci funkcí $f_X,f_Y$, neboli
    \[f_Z(z) = \int^\infty_{-\infty}f_X(x)f_Y(z-x)dx\]
    \begin{proof}
        Náhled: \[P(Z=z | X=x) = P(Y = z-x)\]
        \[f_{Z|X}(z|x) = f_Y(z-x)\]
        (n.v. $Z|X=x$ je stejná jako $Y+x$)
        \[f_Z(z) = \int^\infty_{-\infty} f_{Z|X} (z|x)f_X(x) =\]
        \[=\int f_Y(z-x)f_X(x)\]
    \end{proof}
\end{theorem}

\begin{example}
    $X,Y \sim N(0,1)$ nezávislé. n.v. \dots $f_X = f_Y = \varphi$ \dots $\varphi(t) = \frac{1}{\sqrt{2\pi}}e^{-\frac{t^2}{2}}$
    \[Z = X+Y\]
    \[f_Z(z) = \int^\infty_{-\infty} f_X(x)f_Y(z-x)dx=\]
    \[= \int^\infty_{-\infty} \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}} \frac{1}{\sqrt(2\pi)}e^{-\frac{(z-x)^2}{2}}dx\]
    \[= \frac{1}{2\pi} e^{-\frac{z^2}{2}}\int^\infty_{-\infty}e^{-x^2 + zx}dx\]
    \[= \frac{1}{2\pi} e^{-\frac{z^2}{2}+\frac{z^2}{4}} \int e^{-(x-\frac{z}{2})^2}dx\]
    \[= \frac{1}{\sqrt{2}\sqrt{2\pi}} e^{-\frac{z^2}{4}} \dots \text{ hustota } N(0,2) \]
\end{example}

\begin{definition}
    Podmíněná hustota a střední hodnota\\

    \begin{enumerate}
        \item $\mathbb{E}(X|B) := \int^\infty_{-\infty} xf_{X|B}(x)dx$
        \item $\mathbb{E}(g(X)|B):=\int^\infty_{-\infty}g(x)f_{X|B}(x)dx$
    \end{enumerate}
\end{definition}
\begin{theorem}
    Věta o úplné střední hodnotě\\

    Nechť $X$ je spojitá n.v.. Pokud $B_1,B_2,\dots$ je rozklad, tak
    \[\mathbb{E}(X) = \sum_i P(B_i)\mathbb{E}(X|B_i).\]
    Důkaz: pomocí rozkladu hustoty:
    \[\int xf_X(x) = \int^\infty_{-\infty} x\sum_i P(B_i) f_{X|B}(x) = \sum_i P(B_i) \int x f_{X|B_i} (x)\]
\end{theorem}

\begin{definition}
    Podmíněná hustota a střední hodnota
    \begin{enumerate}
        \item $f_{X|Y}(x|y) := \frac{f_{X,Y}(x,y)}{f_Y(y)}$ je hustota n.v. $X$, pokud $Y = y$
        \item $\mathbb{E}(X|Y=y):=\int xf_{X|Y}(x,y)dx$ je střední hodnota této veličiny
        \item $\mathbb{E}(g(X)|Y=y) = \int g(x)f_{X|Y}(x,y)dx$
        \item Analogie věty o úplné střední hodnotě:
        \[\mathbb{E}(X) = \int^\infty_{-\infty}\mathbb{E}(X|Y=y)f_Y(y)dy\]
        \item $\mathbb{E}(X) = \mathbb{E}(\mathbb{E}(X|Y))$
    \end{enumerate}
\end{definition}
\begin{definition}
    Kovariance\\

    Pro n.v. $X,Y$ definujeme jejich kovarianci předpisem
    \[cov(X,Y) = \mathbb{E}((X-\mathbb{E}X)(Y-\mathbb{E}Y)).\]
    Věta:
    \[cov(X,Y) = \mathbb{E}(XY) - \mathbb{E}(X)\mathbb{E}(Y).\]
    \begin{enumerate}
        \item $var(X) = cov(X,X)$
        \item $cov(X,\alpha Y + \beta Z + c) = \alpha\ cov(X,Y) + \beta\ cov(X,Z)$
        \item $cov(X,Y) = 0$ pokud $X,Y$ jsou nezávislé
        \item ale nejen tehdy
    \end{enumerate}
\end{definition}
\begin{definition}
    Korelace\\

    Korelace náhodných veličin $X,Y$ je definovaná předisem
    \[\varrho (X,Y) = \frac{cov(X,Y)}{\sqrt{var(X)var(Y)}}.\]
    \begin{enumerate}
        \item je to "přenormovaná" kovariance
        \item $-1 \leq \varrho(X,Y) \leq 1$.
        \item Korelace neznamená příčinnou souvislot! (Např. korelace je symetrická, kauzalita nikoli!)
        \item Naopak, nekorelace neznamená nezávislost. (Př. $X$ libovolná, $Y = +X$ nebo $Y = -X$, obojí se stejnou pravděpodobností).    \end{enumerate}
\end{definition}
\begin{theorem}
    Rozptyl součtu\\

    Nechť $X = \sum^n_{i=1}X_i$. Pak
    \[var(X) = \sum^n_{i=1}\sum^n_{j=1}cov(X_i,X_j) = \sum^n_{i=1}var(X_i) + \sum_{i\neq j} cov(X_i,X_j).\]
    Sec. jsou $X_1, \dots, X_n$ nezávislé, pak
    \[var(X) = \sum^n_{i=1}var(X_i)\]
    \begin{proof}
        \[var(X) = \mathbb{E}(\sum X_i \times \sum X_j) - (\sum \mathbb{E}X_i)(\sum \mathbb{E}X_j)\]
        \[= \mathbb{E}(\sum X_iX_j) - \sum \mathbb{E}(X_i)\mathbb{E}(X_j)\]
    \end{proof}
\end{theorem}

\begin{theorem}
    Cauchyho nerovnost\\
    \[\mathbb{E}(XY) \leq \sqrt{\mathbb{E}(X^2)\mathbb{E}(Y^2)}\]
    \begin{proof}
        jako v LA, součin norem 
    \end{proof}

    \begin{remark}
        Důsledek pro korelaci: $-1 \leq \varrho(X,Y) \leq 1$
    \end{remark}
\end{theorem}

\begin{theorem}
    Jensenova věta\\

    Nechť $X$ má konečnou střední hodnotu a nechť $g$ je konvexní reálná funkce. Pak 
    \[\mathbb{E}(g(X))\geq g(\mathbb{E}(X)).\]
    \begin{proof}
        \[\mu = \mathbb{E}(X)\]
        \[L(\mu) = g(\mu)\]
        \[\forall t L(t) \leq g(t) ... \text{$L(t)$ je tečna $g(t)$ v bodě $\mu$}\]
        \[L(X) \leq g(X)\]
        \[\mathbb{E}L(X) \leq \mathbb{E}g(X)\]
        \[\text{z linearity $L$}\]
        \[L(\mathbb{E}X) = g(\mathbb{E}(X))\]
    \end{proof}
\end{theorem}

\begin{theorem}
    Markovova nerovnost\\

    Nechť náhodná veličina $X$ splňuje $X\geq 0$. Pak
    \[P(X\geq a) \leq \frac{\mathbb{E}(X)}{a}\]
    \begin{proof}
        \[\mathbb{E}(X) = P(X\geq a)\mathbb{E}(X|X\geq a) + P(X< a) \mathbb{E}(X|X<a)\]
        \[ \mathbb{E}(X) \geq P(X\geq a)a\]
    \end{proof}
\end{theorem}
\begin{theorem}
    Čebyševova nerovnost\\

    Nechť $X$ má konečnou střední hodnotu $\mu$ a rozptyl $\sigma^2$. Pak
    \[P(|X-\mu|\geq a\sigma)\leq \frac{1}{a^2}\]
    \begin{proof}
        \[Y = (X-\mu)^2\]
        \[P(Y\geq a^2\sigma^2) \leq \frac{\mathbb{E}(Y)}{a^2\sigma^2}= \frac{var(X)}{a^2\sigma^2}\]
    \end{proof}
\end{theorem} 
\begin{theorem}
    Černovova nerovnost\\

    Nechť $X = \sum^n_{i=1} X_i$, kde $X_i$ jsou n.n.v. nabývající hodnot $\pm 1$ s pravděpodobností $1/2$. Pak pro $t>0$ platí:
    \[P(X\leq -t) = P(X\geq t) \leq e^{-\frac{t^2}{2\sigma^2}},\]
    kde $\sigma = \sigma_X = \sqrt{n}$ 
\end{theorem}
\end{document}
